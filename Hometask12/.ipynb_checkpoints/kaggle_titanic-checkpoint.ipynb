{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home task: Kaggle Competition [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_DIR = os.path.join(CWD, 'titanic_data')\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, 'train.csv')\n",
    "TEST_FILE = os.path.join(DATA_DIR, 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "train_data = pd.read_csv(TRAIN_FILE)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the train dataset we have 12 columns:\n",
    " - `PassengerId` - passenger id\n",
    " - `Survived` - survival (0 = No, 1 = Yes)\n",
    " - `Pclass` - ticket class (1 = 1st, 2 = 2nd, 3 = 3rd): a proxy for socio-economic status (1st = upper, 2nd = middle, 3rd = lower)\n",
    " - `Name` - passenger name\n",
    " - `Sex` - passenger sex\n",
    " - `Age` - passenger age in years: age is fractional if less than 1; if age is estimated, is it in the form of xx.5\n",
    " - `SibSp` - number of siblings/spouses aboard the Titanic: sibling = brother, sister, stepbrother, stepsister; spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    " - `Parch` - number of parents/children aboard the Titanic: parent = mother, father; child = daughter, son, stepdaughter, stepson; some children travelled only with a nanny, therefore parch = 0 for them\n",
    " - `Ticket` - ticket number\n",
    " - `Fare` - passenger fare\n",
    " - `Cabin` - cabin number\n",
    " - `Embarked` - port of embarkation\t(C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns `PassengerId`, `Name`, `Ticket` and `Cabin` are irrelevent for prediction whether the passenger were survived, so we will ignore them.\n",
    "\n",
    "Now let's build the plots of column values depending on whether the passenger were survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 4))\n",
    "\n",
    "# Bar chart of Pclass column depending on passenger survival\n",
    "plt.subplot(1, 3, 1, ylabel='Count')\n",
    "sns.countplot(train_data, x='Pclass', hue='Survived')\n",
    "\n",
    "# Histogram of Age column depending on passenger survival\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(train_data, x='Age', hue='Survived', bins=10)\n",
    "\n",
    "# Bar chart of Sex column depending on passenger survival\n",
    "plt.subplot(1, 3, 3, ylabel='Count')\n",
    "sns.countplot(train_data, x='Sex', hue='Survived');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot (`Pclass` column) shows us that the higher the ticket class (from 3rd to 1st), the higher the survival rate. In the 1st class number of passengers who survived higher than the number of passengers who did not survived.\n",
    "\n",
    "In the second plot (`Age` column) we can see that survival rate is low among adult passengers. However, most child passengers under the age of 10 were survived.\n",
    "\n",
    "The third plot (`Sex` column) shows that the survival rate among female passengers is higher than male passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 4))\n",
    "\n",
    "# Histogram of SibSp column depending on passenger survival\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(train_data, x='SibSp', hue='Survived', discrete=True)\n",
    "\n",
    "# Histogram of Parch column depending on passenger survival\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(train_data, x='Parch', hue='Survived', discrete=True)\n",
    "\n",
    "# Histogram of Fare column depending on passenger survival\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(train_data, x='Fare', hue='Survived', bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first and second plots (columns `SibSp` and `Parch`) we can see that number of siblings/spouses or parents/children aboard does not affect the survival ratio. However, it is worth noting that for passengers who had one sibling/spouse or parent/child aboard survival ratio is higher.\n",
    "\n",
    "The third plot (`Fare` column) shows us that the survival ratio is higher among passengers who have paid between 50 and 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of Embarked column depending on passenger survival\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.ylabel('Count')\n",
    "sns.countplot(train_data, x='Embarked', hue='Survived');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that the survival ratio is the highest among passengers who have embarked from Cherbourg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start cleaning the data, we need to analyze the data types in different columns determine if there are NA values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, `Age` column has 177 NA values and `Embarked` column has 2 NA values (`Cabin` column is ignored). For further forecasting we need fill in the NA values in these columns with the aggregated values from dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new column which contains passenger initials (honorifics): Mr, Miss, Mrs, Sir, Lady etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initials = train_data['Name'].str.extract('(\\w+)\\.').squeeze()\n",
    "initials.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we reduce the number of possible passenger initials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initials.replace(\n",
    "    ['Mlle', 'Mme', 'Ms'] +                  # To Miss\n",
    "    ['Lady', 'Countess'] +                   # To Mrs\n",
    "    ['Dr', 'Major', 'Capt', 'Sir', 'Don'] +  # To Mr\n",
    "    ['Jonkheer', 'Col', 'Rev'],              # To Other\n",
    "    ['Miss'] * 3 + ['Mrs'] * 2 + ['Mr'] * 5 + ['Other'] * 3,\n",
    "    inplace=True\n",
    ")\n",
    "initials.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can fill in the NA values in `Age` column with the age mean values for different passenger initials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age mean values for different passenger initials (estimation can be xx.0 or xx.5)\n",
    "age_means = train_data.groupby(initials)['Age'].mean().round(1)\n",
    "age_means - (age_means % 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill in the NA values in `Embarked` column with the most common value in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common embarkation value (mode)\n",
    "train_data['Embarked'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we investigate the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_data = pd.read_csv(TEST_FILE)\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will also determine if the dataset contains NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test dataset `Age` column has 86 NA values and `Fare` column has one NA value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill in the NA values in `Age` column, we follow the same process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initials = test_data['Name'].str.extract('(\\w+)\\.').squeeze()\n",
    "initials.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initials.replace(\n",
    "    ['Ms'] +            # To Miss\n",
    "    ['Lady', 'Dona'] +  # To Mrs\n",
    "    ['Dr'] +            # To Mr\n",
    "    ['Col', 'Rev'],     # To Other\n",
    "    ['Miss'] + ['Mrs'] * 2 + ['Mr'] + ['Other'] * 2,\n",
    "    inplace=True\n",
    ")\n",
    "initials.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age mean values for different passenger initials (estimation can be xx.0 or xx.5)\n",
    "age_means = test_data.groupby(initials)['Age'].mean().round(1)\n",
    "age_means - (age_means % 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill in the NA values in `Fare` column, we can use the average value in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average fare value\n",
    "test_data['Fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to apply cleaning process to train and test dataset, we create clean_titanic_data function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_titanic_data(data, return_y=True):\n",
    "    '''\n",
    "    Performs data cleaning in titanic dataset.\n",
    "\n",
    "    :param data: A dataset\n",
    "    :type data: DataFrame\n",
    "    :param return_y: If `True`, returns `(ids, X, y)`, if `False`, returns `(ids, X)`\n",
    "    :type return_y: bool\n",
    "\n",
    "    :raises TypeError: Occurs if `data` does not contain `Survived` column when `return_y=True`\n",
    "\n",
    "    :return: `(ids, X, y)` or `(ids, X)` where `ids` is passenger ids, ndarray of shape (?,),\n",
    "    `X` is features values, ndarray of shape (?, n), `y` is target values, ndarray of shape (?,)\n",
    "    :rtype: tuple[ndarray, ndarray, ndarray] | tuple[ndarray, ndarray]\n",
    "    '''\n",
    "    \n",
    "    # Copy the dataset\n",
    "    titanic = data.copy()\n",
    "\n",
    "    # Create columns of passenger initials (honorifics)\n",
    "    titanic['Initial'] = titanic['Name'].str.extract('(\\w+)\\.')\n",
    "    titanic['Initial'] = titanic['Initial'].replace(\n",
    "        ['Mlle', 'Mme', 'Ms'] +                  # Replace to Miss\n",
    "        ['Lady', 'Countess', 'Dona'] +           # Replace to Mrs\n",
    "        ['Dr', 'Major', 'Capt', 'Sir', 'Don'] +  # Replace to Mr\n",
    "        ['Jonkheer', 'Col', 'Rev'],              # Replace to Other\n",
    "        ['Miss'] * 3 + ['Mrs'] * 3 + ['Mr'] * 5 + ['Other'] * 3\n",
    "    )\n",
    "\n",
    "    # Fill in NA values in Age column with age mean values for different passenger initials\n",
    "    age_means = titanic.groupby('Initial')['Age'].mean().round(1)\n",
    "    age_means -= age_means % 0.5\n",
    "    titanic.loc[data['Age'].isna(), 'Age'] = titanic.loc[data['Age'].isna(), 'Initial'].map(age_means.to_dict())\n",
    "\n",
    "    # Fill in NA values in Fare column with fare average value\n",
    "    fare_mean = titanic['Fare'].mean()\n",
    "    titanic['Fare'] = titanic['Fare'].fillna(fare_mean)\n",
    "\n",
    "    # Fill in NA values in Embarked column with embarkation mode value\n",
    "    embarkation_mode = titanic['Embarked'].value_counts().index[0]\n",
    "    titanic['Embarked'] = titanic['Embarked'].fillna(embarkation_mode)\n",
    "\n",
    "    # Convert values in Sex column to numeric\n",
    "    titanic['Sex'] = titanic['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "    # Create dummy features which represent unique values in Embarked column\n",
    "    embarkations = pd.get_dummies(titanic['Embarked'], prefix='Embarked', dtype='int')\n",
    "    titanic = pd.concat([titanic, embarkations], axis=1)\n",
    "\n",
    "    # Name of passenger id column\n",
    "    id_feature = 'PassengerId'\n",
    "\n",
    "    # Names of feature columns and target column\n",
    "    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare'] + embarkations.columns.to_list()\n",
    "    target = 'Survived'\n",
    "\n",
    "    # Return ids values, feature values and target values\n",
    "    if return_y:\n",
    "        if target not in titanic.columns:\n",
    "            raise TypeError(f'Dataset does not contain a {target} column')\n",
    "        return titanic[id_feature].values, titanic[features].values, titanic[target].values\n",
    "    \n",
    "    # Return only ids values and feature values\n",
    "    else:\n",
    "        return titanic[id_feature].values, titanic[features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Models Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean train dataset\n",
    "_, X_train, y_train = clean_titanic_data(train_data, return_y=True)\n",
    "print(f'Shape of features: {X_train.shape}')\n",
    "print(f'Shape of targets: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize dataset using min-max scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors (KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "clf = KNeighborsClassifier()\n",
    "params = {'n_neighbors': list(range(3, 20))}\n",
    "grid_clf = GridSearchCV(clf, params).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Best parameters (KNeighborsClassifier):', grid_clf.best_params_)\n",
    "print('Best score (accuracy):', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "clf = LogisticRegression()\n",
    "params = {'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]}\n",
    "grid_clf = GridSearchCV(clf, params).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Best parameters (LogisticRegression):', grid_clf.best_params_)\n",
    "print('Best score (accuracy):', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "clf = SVC()\n",
    "params = [\n",
    "    {'kernel': 'linear', 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]},\n",
    "    {'kernel': 'poly', 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10], 'degree': [2, 3, 4, 5]},\n",
    "    {'kernel': 'rbf', 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10], \n",
    "     'gamma': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 10, 50, 100]}\n",
    "]\n",
    "grid_clf = GridSearchCV(clf, params).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Best parameters (SVC):', grid_clf.best_params_)\n",
    "print('Best score (accuracy):', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max accuracy): {'C': 5}\n",
      "Grid best score (accuracy): 0.8099203231960498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "grid_clf = GridSearchCV(clf, {'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]}, return_train_score=True)\n",
    "\n",
    "grid_clf.fit(X_train_scaled, y_train)\n",
    "print('Grid best parameter (max accuracy):', grid_clf.best_params_)\n",
    "print('Grid best score (accuracy):', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max accuracy): {'n_neighbors': 3}\n",
      "Grid best score (accuracy): 0.7979014700931433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "grid_clf = GridSearchCV(clf, {'n_neighbors': [3, 5, 7, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]}, return_train_score=True)\n",
    "\n",
    "grid_clf.fit(X_train_scaled, y_train)\n",
    "print('Grid best parameter (max accuracy):', grid_clf.best_params_)\n",
    "print('Grid best score (accuracy):', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max accuracy): {'C': 5, 'gamma': 10}\n",
      "Grid best score (accuracy): 0.8129278419930424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "grid_clf = GridSearchCV(\n",
    "    clf, \n",
    "    {'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10], 'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100]},\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_clf.fit(X_train_scaled, y_train)\n",
    "print('Grid best parameter (max accuracy):', grid_clf.best_params_)\n",
    "print('Grid best score (accuracy):', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max accuracy): {'criterion': 'gini', 'max_depth': 5}\n",
      "Grid best score (accuracy): 0.817383009763214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=2023)\n",
    "grid_clf = GridSearchCV(\n",
    "    clf, \n",
    "    {'criterion': ['gini', 'entropy'], 'max_depth': [2, 5, 7, 10, 20, 30, 35, 40, 50, 100]},\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_clf.fit(X_train_scaled, y_train)\n",
    "print('Grid best parameter (max accuracy):', grid_clf.best_params_)\n",
    "print('Grid best score (accuracy):', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max accuracy): {'criterion': 'gini', 'n_estimators': 300}\n",
      "Grid best score (accuracy): 0.8114689709347997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=2023)\n",
    "grid_clf = GridSearchCV(\n",
    "    clf, \n",
    "    {'criterion': ['gini', 'entropy', 'log_loss'], 'n_estimators': [20, 50, 100, 150, 200, 250, 300]},\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_clf.fit(X_train_scaled, y_train)\n",
    "print('Grid best parameter (max accuracy):', grid_clf.best_params_)\n",
    "print('Grid best score (accuracy):', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max accuracy): {'learning_rate': 0.05, 'n_estimators': 200}\n",
      "Grid best score (accuracy): 0.8368308831780945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=2023)\n",
    "grid_clf = GridSearchCV(\n",
    "    clf, \n",
    "    {'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10], 'n_estimators': [20, 50, 100, 150, 200, 250, 300]},\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_clf.fit(X_train_scaled, y_train)\n",
    "print('Grid best parameter (max accuracy):', grid_clf.best_params_)\n",
    "print('Grid best score (accuracy):', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\DS_Camp_2023\\Hometask12\\supervised_ml_cover.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf \u001b[39m=\u001b[39m XGBClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m2023\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m grid_clf \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     clf, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     {\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m35\u001b[39m, \u001b[39m40\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m100\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.01\u001b[39m, \u001b[39m0.02\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m20\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m150\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m250\u001b[39m, \u001b[39m300\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mreg_lambda\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.001\u001b[39m, \u001b[39m0.005\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m]},\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m grid_clf\u001b[39m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGrid best parameter (max accuracy):\u001b[39m\u001b[39m'\u001b[39m, grid_clf\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DS_Camp_2023/Hometask12/supervised_ml_cover.ipynb#X62sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGrid best score (accuracy):\u001b[39m\u001b[39m'\u001b[39m, grid_clf\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1491\u001b[0m     params,\n\u001b[0;32m   1492\u001b[0m     train_dmatrix,\n\u001b[0;32m   1493\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39mevals,\n\u001b[0;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39mevals_result,\n\u001b[0;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39mobj,\n\u001b[0;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39mmetric,\n\u001b[0;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m   1502\u001b[0m )\n\u001b[0;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\XTreme.ws\\anaconda3\\envs\\ds-camp\\Lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(random_state=2023)\n",
    "grid_clf = GridSearchCV(\n",
    "    clf, \n",
    "    {'max_depth': [2, 5, 7, 10, 20, 30, 35, 40, 50, 100], 'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10],\n",
    "     'n_estimators': [20, 50, 100, 150, 200, 250, 300], 'reg_lambda': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]},\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_clf.fit(X_train_scaled, y_train)\n",
    "print('Grid best parameter (max accuracy):', grid_clf.best_params_)\n",
    "print('Grid best score (accuracy):', grid_clf.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
